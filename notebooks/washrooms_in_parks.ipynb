{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12a9c6f6",
   "metadata": {},
   "source": [
    "# Predicting breast cancer from digitized images of breast mass\n",
    "\n",
    "by Rebecca Sokol-Snyder, William Song, and Chung Ki (Harry) Yau 2025/11/22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f0013b",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "We retrieved the public Park data from the City of Vancouver Open Data Portal. We aim to construct a classification model using the adequate algorithm to help us evaluate the factors that influenced the construction of washroom which is one of the important amenities in public parks. We used two models, KNN and SVM RBVF, to test our data.\n",
    "\n",
    "The cross-validation result shows that SVM RBF provides a small but consistent improvement over the baseline, while KNN overfits and fails to generalize. The dataset may require richer features or alternative models to achieve stronger predictive performance on washroom availability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eedaaaa",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "The Vancouver parks dataset (City of Vancouver 2025) offers a comprehensive view of the city’s green spaces, capturing details from park names and neighbourhoods to special features and facilities. The Washrooms column is particularly valuable, as it reveals which parks provide public washrooms and which do not. By linking this information to neighbourhoods and park sizes, the dataset becomes a powerful tool for assessing accessibility and identifying gaps in essential amenities across Vancouver’s park system.\n",
    "\n",
    "By treating washroom presence as a target variable, we wonder if we can use machine learning algorithm to help us predict where facilities are most needed, identify underserved neighbourhoods, and optimize future installations. Using features such as park size, amenities, and neighbourhood context, ML models can uncover hidden patterns in service distribution and guide equitable infrastructure planning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02b7db4",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "\n",
    "### Data\n",
    "The data set that was used in this project is from City of Vancouver Open Data Portal. There are over 220 parks and 40 major facilities in the city of Vancouver maintained by the Vancouver Board of Parks and Recreation. In the data set, it has covered 218 park information regarding facilities available to the parks, their locations, and sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45707f40-dba2-4578-9892-c939647dae01",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "We compared the performance of a k-nearest neighbors (k-nn) algorithm and a Support Vector Machine with Radial Basis Function (SVM RBF) algorithm to build a binary classification model to predict whether a park has washrooms or not. We included neighbourhood name, park size (hectare), whether the park is official, whether there are any advisories, whether there are additional facilities and whether the park has special features to fit the model. Data was split with 70% of the original dataset in the training set and the remaining 30% in the test set. We conducted 5-fold cross-validation to compare the models with a baseline. All variables preprocessed just before model fitting to ensure reliability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5069d124",
   "metadata": {},
   "source": [
    "## Results and Discussion\n",
    "To look at whether the chosen features might be helpful in predicting the existance of washrooms in Vancouver parks we began with some Exploratory Data Analysis (EDA). We analyze the counts of binary features in parks based on the presence of washrooms to identify patterns in park amenities. The results shows that parks with washrooms tend to be associated with  higher counts of other amenities compared to those without washrooms. We then used a histogram to visualize the the number of hectares of a park based on the presence of washrooms.We can see a significant difference in the hectare size of a park when washrooms are present or not. The parks with washrooms tend to be larger in size compared to those without washrooms. Finally, categorical features are also visualized using bar charts to show the distribution of different categories based on the presence of washrooms in parks. \n",
    "\n",
    "3 models were used to predict the presence of washrooms in parks based on the binary, numeric and categorical features. The models used were KNN, SVC with RBF kernal and Dummy classification. The performance of each model was evaluated using cross validation score. The results indicate that the SVC with RBF kernal model had a better performance than the other two models in predicting the presence of washrooms in parks.\n",
    "\n",
    "The analysis reveals that parks equipped with washrooms generally offer a wider range of amenities and larger hectare compared to those without washrooms. This suggests that parks with washrooms may be designed to accommodate more visitors and provide a more comprehensive recreational experience. The presence of washrooms could be an indicator of a park's overall quality and the level of services it provides to the public."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26d38ed6-c9c9-435e-98b9-72c1cc3a5810",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandera'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mneighbors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KNeighborsClassifier\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ConfusionMatrixDisplay\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandera\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpa\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdeepchecks\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtabular\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdeepchecks\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtabular\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchecks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FeatureLabelCorrelation\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandera'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import logging\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import pandera.pandas as pa\n",
    "from deepchecks.tabular import Dataset\n",
    "from deepchecks.tabular.checks import FeatureLabelCorrelation\n",
    "from deepchecks.tabular.checks.data_integrity import FeatureFeatureCorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455f47e9-d61d-4617-99e2-9d5330ec73f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "\n",
    "# Data Validation: correct file format\n",
    "try: \n",
    "    park = pd.read_csv(\"https://opendata.vancouver.ca/api/explore/v2.1/catalog/datasets/parks/exports/csv?lang=en&timezone=America%2FLos_Angeles&use_labels=true&delimiter=%3B\", sep=\";\")\n",
    "except:\n",
    "    raise Exception(\"File appears to be in the incorrect format!\")\n",
    "park.to_csv(\"../data/parks.csv\", sep=';')\n",
    "park"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46adc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandera data validation\n",
    "# no check for missingness threshold since the only nullable columns are dropped\n",
    "# so we do not care about how many nulls there are\n",
    "\n",
    "# set up invalid data logging\n",
    "# adapted from DSCI 522 Textbook\n",
    "logging.basicConfig(\n",
    "    filename=\"../logs/validation_errors.log\",\n",
    "    filemode=\"w\",\n",
    "    format=\"%(asctime)s - %(message)s\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "\n",
    "# Configure valid data schema\n",
    "schema = pa.DataFrameSchema(\n",
    "    {\n",
    "        \"ParkID\": pa.Column(int),\n",
    "        \"Name\": pa.Column(str),\n",
    "        \"Official\": pa.Column(int, pa.Check.isin([0,1])),\n",
    "        \"Advisories\": pa.Column(str, pa.Check.isin([\"Y\", \"N\"])),\n",
    "        \"SpecialFeatures\": pa.Column(str, pa.Check.isin([\"Y\", \"N\"])),\n",
    "        \"Facilities\": pa.Column(str, pa.Check.isin([\"Y\", \"N\"])),\n",
    "        \"Washrooms\": pa.Column(str, pa.Check.isin([\"Y\", \"N\"])),\n",
    "        \"StreetNumber\": pa.Column(int, pa.Check.between(1, 10000), required=False),\n",
    "        \"StreetName\": pa.Column(str, required=False),\n",
    "        \"EWStreet\": pa.Column(str, nullable=True, required=False),\n",
    "        \"NSStreet\": pa.Column(str, nullable=True, required=False),\n",
    "        \"NeighbourhoodName\": pa.Column(str, pa.Check.isin([\n",
    "            \"Arbutus-Ridge\",\n",
    "            \"Downtown\",\n",
    "            \"Dunbar-Southlands\",\n",
    "            \"Fairview\",\n",
    "            \"Grandview-Woodland\",\n",
    "            \"Hastings-Sunrise\",\n",
    "            \"Kensington-Cedar Cottage\",\n",
    "            \"Kerrisdale\",\n",
    "            \"Killarney\",\n",
    "            \"Kitsilano\",\n",
    "            \"Mount Pleasant\",\n",
    "            \"South Cambie\",\n",
    "            \"Renfrew-Collingwood\",\n",
    "            \"Oakridge\",\n",
    "            \"Riley Park\",\n",
    "            \"Shaughnessy\",\n",
    "            \"Victoria-Fraserview\",\n",
    "            \"West End\",\n",
    "            \"West Point Grey\",\n",
    "            \"Marpole\",\n",
    "            \"Strathcona\",\n",
    "            \"Sunset\"\n",
    "        ])),\n",
    "        \"NeighbourhoodURL\": pa.Column(str, \n",
    "            checks=[\n",
    "                pa.Check(lambda url: url.str.startswith(\"https://vancouver.ca\")),\n",
    "                pa.Check(lambda url: url.str.endswith(\".aspx\"))\n",
    "            ],\n",
    "            nullable=True\n",
    "        ),\n",
    "        \"Hectare\": pa.Column(float, pa.Check.between(0, 400)),\n",
    "        \"GoogleMapDest\": pa.Column(str, \n",
    "            pa.Check(lambda latlon: latlon.str.startswith(\"49.\")),\n",
    "            nullable=True\n",
    "        )\n",
    "    },\n",
    "    checks=[\n",
    "        pa.Check(lambda df: ~df.duplicated().any(), error = \"Duplicate Rows!\"),\n",
    "        pa.Check(lambda df: ~(df.isna().all(axis=1)).any(), error = \"Empty Rows!\")\n",
    "    ],\n",
    "    drop_invalid_rows=False\n",
    ")\n",
    "\n",
    "# Adapted from DSCI 522 Textbook\n",
    "# Initialize error cases DataFrame\n",
    "error_cases = pd.DataFrame()\n",
    "data = park.copy()\n",
    "\n",
    "# Adapted from DSCI 522 Textbook\n",
    "# Validate data and handle errors\n",
    "try:\n",
    "    park = schema.validate(data, lazy=True)\n",
    "except pa.errors.SchemaErrors as e:\n",
    "    error_cases = e.failure_cases\n",
    "\n",
    "    # Adapted from DSCI 522 Textbook\n",
    "    # Convert the error message to a JSON string\n",
    "    error_message = json.dumps(e.message, indent=2)\n",
    "    logging.error(\"\\n\" + error_message)\n",
    "\n",
    "# Filter out invalid rows based on the error cases\n",
    "if not error_cases.empty:\n",
    "    invalid_indices = error_cases[\"index\"].dropna().unique()\n",
    "    park = (\n",
    "        data.drop(index=invalid_indices)\n",
    "        .reset_index(drop=True)\n",
    "        .drop_duplicates()\n",
    "        .dropna(how=\"all\")\n",
    "    )\n",
    "else:\n",
    "    park = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1a657c-c9ba-480a-aeda-8ed88f1660ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test data set up\n",
    "train_df, test_df = train_test_split(park, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d3b2f7-7fff-4bbe-8781-60cfb25a7172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Validation Pandera check of target distribution\n",
    "\n",
    "training_schema = pa.DataFrameSchema({\n",
    "    \"Washrooms\": pa.Column(str, checks = [\n",
    "        pa.Check(\n",
    "            lambda w: (w == \"Y\").sum() / len(w) >= 0.2, \n",
    "            element_wise=False,\n",
    "            error=\"Target Class may be imbalanced, check source data!\"\n",
    "        ),\n",
    "        pa.Check(\n",
    "            lambda w: (w == \"N\").sum() / len(w) >= 0.2, \n",
    "            element_wise=False,\n",
    "            error=\"Target Class may be imbalanced, check source data!\"\n",
    "        )\n",
    "                                    ])\n",
    "})\n",
    "\n",
    "train_df = training_schema.validate(train_df, lazy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f027c4c-d86d-4375-b25e-81ae727dcc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# listing features in dataframe\n",
    "numeric_features = ['Hectare']\n",
    "categorical_features = ['NeighbourhoodName']\n",
    "binary_features = ['Official', 'Advisories', 'SpecialFeatures', 'Facilities']\n",
    "drop_features = ['NeighbourhoodURL', 'ParkID', 'Name', 'GoogleMapDest', 'StreetNumber', 'StreetName', 'EWStreet', 'NSStreet']\n",
    "target = \"Washrooms\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c53c3f-f645-4890-871c-143f99062220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No anomalous correlations between target/response variable and features/explanatory variables\n",
    "# Using Deepchecks Feature Label Correlation check\n",
    "\n",
    "# Prepare dataset that matches Deepcheck syntax\n",
    "dc_categorical_features = ['NeighbourhoodName', 'Official', 'Advisories', 'SpecialFeatures', 'Facilities']\n",
    "dc_train_df = train_df.drop(columns = drop_features)\n",
    "dc_test_df = test_df.drop(columns = drop_features)\n",
    "\n",
    "# Checking procedure and result\n",
    "fl_check_ds = Dataset(dc_train_df, label=target, cat_features=dc_categorical_features)\n",
    "my_check = FeatureLabelCorrelation()\n",
    "my_check.run(dataset=fl_check_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5c33d2-7851-4a6b-aec1-1f418bb0f2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No anomalous correlations between features/explanatory variables\n",
    "# Using Deepchecks Feature Feature Correlation check\n",
    "\n",
    "# Checking procedure and result\n",
    "ff_check_ds = Dataset(dc_train_df, cat_features=dc_categorical_features)\n",
    "check = FeatureFeatureCorrelation()\n",
    "check.add_condition_max_number_of_pairs_above_threshold(0.7, 3) # add self-defined threshold condition\n",
    "check.run(ff_check_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f025f9fe-da7a-4c9e-be84-bdb5a70d4ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of dataframe\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8ff436",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c21e6c5-a3ea-4291-af55-0689ce27b95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize numeric features\n",
    "for col in numeric_features:\n",
    "    train_df.groupby(target)[col].plot.hist(bins=50, alpha=0.5, legend=True)\n",
    "    plt.xlabel(col);\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03bc855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize categorical features\n",
    "col = 'NeighbourhoodName'\n",
    "cat_df = train_df[[col, target]].copy()\n",
    "cat_df_count = cat_df.groupby([target, col]).size().unstack()\n",
    "cat_df_count.plot.bar()\n",
    "plt.title(col);\n",
    "plt.legend(title=col, bbox_to_anchor=(1.05, 1), loc='upper left');\n",
    "plt.xlabel(col);\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff500a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize binary features when there is washroom\n",
    "binary_df = train_df[binary_features + [target]].copy()\n",
    "binary_df['Official'] = binary_df['Official'].astype(str).replace({\"1\": \"Y\", \"0\": \"N\"})\n",
    "washroom_df = binary_df[binary_df[target] == \"Y\"]\n",
    "washroom_df_count = washroom_df.groupby(target)[binary_features].apply(lambda group: (group == \"Y\").sum())\n",
    "washroom_df_count\n",
    "washroom_df_count.plot.bar()\n",
    "plt.title(\"Count of Binary Features when Washrooms are Present\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd25668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize binary features when there is no washroom\n",
    "no_washroom_df = binary_df[binary_df[target] == \"N\"]\n",
    "no_washroom_df_count = no_washroom_df.groupby(target)[binary_features].apply(lambda group: (group == \"Y\").sum())\n",
    "no_washroom_df_count\n",
    "no_washroom_df_count.plot.bar()\n",
    "plt.title(\"Count of Binary Features when Washrooms are Absent\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51411e74-e59b-48e6-a5f2-aeb5df98ee5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns=[target])\n",
    "y_train = train_df[target]\n",
    "X_test = test_df.drop(columns=[target])\n",
    "y_test = test_df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2f2666-3b94-4029-a489-444215059141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessor for column transformation\n",
    "categorical_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy=\"constant\", fill_value=\"missing\"), OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    ")\n",
    "preprocessor = make_column_transformer(\n",
    "    (StandardScaler(), numeric_features),\n",
    "    (OneHotEncoder(), binary_features),\n",
    "    (categorical_transformer, categorical_features),\n",
    "    (\"drop\", drop_features)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c3af2c-abb7-4294-b4e4-6a2f09806955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for cv score, adapted from 571 lab 2\n",
    "def mean_std_cross_val_scores(model, X_train, y_train, **kwargs):\n",
    "    \"\"\"\n",
    "    Returns mean and std of cross validation\n",
    "    Parameters\n",
    "    ----------\n",
    "    model :\n",
    "    scikit-learn model\n",
    "    X_train : numpy array or pandas DataFrame\n",
    "    X in the training data\n",
    "    y_train :\n",
    "    y in the training data\n",
    "    Returns\n",
    "    ----------\n",
    "    pandas Series with mean scores from cross_validation\n",
    "    \"\"\"\n",
    "    scores = cross_validate(model, X_train, y_train, **kwargs)\n",
    "    mean_scores = pd.DataFrame(scores).mean()\n",
    "    std_scores = pd.DataFrame(scores).std()\n",
    "    out_col = []\n",
    "    for i in range(len(mean_scores)):\n",
    "        out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores.iloc[i], std_scores.iloc[i])))\n",
    "    return pd.Series(data=out_col, index=mean_scores.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c946906f-03a2-46be-99ed-73eb54786e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup model and pipline\n",
    "model = DummyClassifier(random_state=123)\n",
    "pipe = make_pipeline(preprocessor, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f0ae1b-158d-4a12-a98b-2b850b635564",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df = pd.DataFrame({\n",
    "    \"dummy\" : mean_std_cross_val_scores(pipe, X_train, y_train, cv=5, return_train_score=True)\n",
    "})\n",
    "dummy_df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c55a540-2a53-4c9f-b1a4-8cf1a81447b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RBF SVC model implementation\n",
    "svm_rbf_classifier = SVC(kernel='rbf', C=1.0, gamma='scale') \n",
    "pipe2 = make_pipeline(preprocessor, svm_rbf_classifier)\n",
    "svm_rbf_df = pd.DataFrame({\n",
    "    \"svm_rbf\" : mean_std_cross_val_scores(pipe2, X_train, y_train, cv=5, return_train_score=True)\n",
    "})\n",
    "svm_rbf_df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346571f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn model implementation\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "pipe3 = make_pipeline(preprocessor, knn_classifier)\n",
    "knn_df = pd.DataFrame({\n",
    "    \"knn\" : mean_std_cross_val_scores(pipe3, X_train, y_train, cv=5, return_train_score=True)\n",
    "})\n",
    "knn_df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c371989",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.merge(dummy_df, svm_rbf_df, left_index=True, right_index=True)\n",
    "result = pd.merge(result, knn_df, left_index=True, right_index=True)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f4219e-4965-4e1b-a1d7-01f9885c6ab7",
   "metadata": {},
   "source": [
    "Since the SVM RBF model performed best on the validation data, we finally fit that model on the entire training set and see how it performs on the test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28043f07-6e02-4779-b948-7b31db8ce536",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2.fit(X_train, y_train)\n",
    "\n",
    "cm = ConfusionMatrixDisplay.from_estimator(\n",
    "    pipe2,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    values_format=\"d\"\n",
    ")\n",
    "cm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b86251",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "City of Vancouver. (2025, September 22). Parks. City of Vancouver Open Data Portal. https://opendata.vancouver.ca/explore/dataset/parks/information/\n",
    "\n",
    "Timbers, T. (n.d.). breast_cancer_predictor_py [Source code]. GitHub. https://github.com/ttimbers/breast_cancer_predictor_py\n",
    "\n",
    "Sci-Kit Learn Documentation. Dummy Classifier. https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html\n",
    "\n",
    "Sci-Kit Learn Documentation. KNeighborsRegressor. https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html\n",
    "\n",
    "Sci-Kit Learn Documentation. SVC. https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
